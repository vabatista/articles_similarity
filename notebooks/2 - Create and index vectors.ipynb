{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599f8429-8b32-45e1-93d3-b7786c375ef9",
   "metadata": {},
   "source": [
    "# 2 - Create vectors from parsed articles and index them\n",
    "\n",
    "In this notebook I read the Json produced before, merge text cells and create a vector representation of each article's full text.\n",
    "\n",
    "I could have used Transformers* library, but since I'm running this demo into my notebook, I adopted Spacy for simplicity. Spacy uses the average vector representation of each token (\"words\"). \n",
    "\n",
    "\\*Since articles full text are bigger than traditional BERT models inputs (i.e. 512 tokens), we must use [Longformer](https://huggingface.co/docs/transformers/model_doc/longformer) to not lose to much content after truncation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec59a1c-3baa-4622-8905-a15e839e641f",
   "metadata": {},
   "source": [
    "## 2.1 - Create Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1550c825-1619-48cb-8b8d-ae3835a8b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0854d431-8305-490a-8a80-8c9722c69efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parsed articles from json\n",
    "with open('../articles.json', 'r') as f:\n",
    "    parsed_articles = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ccd11a-0958-4177-8a96-4f019fd5597b",
   "metadata": {},
   "source": [
    "Here I concatenate all sections text from parsed articles to create a \"full text\" for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1a92f1-e1a6-4b7b-9951-bbd9cab27b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_texts = []\n",
    "for doc in parsed_articles:\n",
    "    text = ' '.join([doc['title'] + ' ' + doc['abstract'] + ' ' + section['text'] for section in doc['sections']])\n",
    "    full_texts.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4bbdec9-4ec7-47ba-8d63-532ce138877c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End-to-End Language Diarization for Bilingual Code-Switching Speech We propose two end-to-end neural configurations for language diarization on bilingual code-switching speech. The first, a BLSTM-E2E architecture, includes a set of stacked bidirectional LSTMs to compute embeddings and incorporates the deep clustering loss to enforce grouping of languages belonging to the same class. The second, an XSA-E2E architecture, is based on an x-vector model followed by a self-attention encoder. The former encodes frame-level features into segmentlevel embeddings while the latter considers all those embeddings to generate a sequence of segment-level language labels. We evaluated the proposed methods on the dataset obtained from the shared task B in WSTCSMC 2020 and our handcrafted simulated data from the SEAME dataset. Experimental results show that our proposed XSA-E2E architecture achieved a relative improvement of 12.1% in equal error rate and a 7.4% relative improvement on accuracy compared \n"
     ]
    }
   ],
   "source": [
    "# print a sample full_text\n",
    "print(random.choice(full_texts)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515b5a7f-18f7-4d1a-ae30-301a67bd5b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(full_texts) == len(parsed_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4572fd5f-dc98-4cac-b6cb-196479ad2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You must install the model into virtual env.\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38857346-6a81-46db-bba3-1c51fde12efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Vector representation for random article\n",
    "doc = nlp(random.choice(full_texts))\n",
    "doc.vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f460a-078a-49c9-b9e3-dd23b96a2b96",
   "metadata": {},
   "source": [
    "As shown above, Spacy produces a 96 positions vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7730429-d95b-48f2-8639-e66480036ad8",
   "metadata": {},
   "source": [
    "## 2.2 Load and save index\n",
    "\n",
    "For creating an index, I'll use Facebook's [Faiss library](https://github.com/facebookresearch/faiss). It is really fast to load and search for vector similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cff0c00-5b10-4c45-a8f5-2a8b281dbaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e844e9-2112-44d3-b6a1-3ba49b7db4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 992/992 [14:25<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors_from_docs = []\n",
    "for full_text in tqdm(full_texts):\n",
    "    doc = nlp(full_text)\n",
    "    vectors_from_docs.append(doc.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4365cd5-a725-41bc-9c34-048ba3a9ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_docs = np.array(vectors_from_docs)\n",
    "index = faiss.IndexFlatL2(arr_docs.shape[1])\n",
    "index.add(arr_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df141ec8-6a8a-49b0-a240-4c161c8af925",
   "metadata": {},
   "source": [
    "## 2.3 Test the index\n",
    "\n",
    "Now I'll test the index by searching an abstract from a random file (this vector representation). I hope it returns the choosen document first :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f324c29e-99f0-45e6-9f53-13ed64a15d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying document id 967 : Factorization-Aware Training of Transformers for Natural Language Understanding On the Edge \n",
      "\n",
      "\n",
      "1 967 Factorization-Aware Training of Transformers for Natural Language Understanding On the Edge  - vector distance:  0.11023985\n",
      "2 812 SynthASR: Unlocking Synthetic Data for Speech Recognition  - vector distance:  0.21954344\n",
      "3 697 Low Resource ASR: The surprising effectiveness of High Resource Transliteration  - vector distance:  0.26151678\n",
      "4 425 Noisy student-teacher training for robust keyword spotting  - vector distance:  0.27137\n",
      "5 136 Enhancing Semantic Understanding with Self-supervised Methods for Abstractive Dialogue Summarization  - vector distance:  0.2738651\n",
      "6 965 Simulating reading mistakes for child speech Transformer-based phone recognition  - vector distance:  0.27791983\n",
      "7 649 Multimodal Speech Summarization through Semantic Concept Learning  - vector distance:  0.27955014\n",
      "8 567 Adjunct-Emeritus Distillation for Semi-Supervised Language Model Adaptation  - vector distance:  0.28254712\n",
      "9 161 Multitask Training with Text Data for End-to-End Speech Recognition  - vector distance:  0.28517902\n",
      "10 579 Leveraging Pre-trained Language Model for Speech Sentiment Analysis  - vector distance:  0.3034777\n"
     ]
    }
   ],
   "source": [
    "n_near_docs = 10\n",
    "\n",
    "idx = random.choice(range(len(full_texts)))\n",
    "print('Querying document id %d : %s' % (idx, parsed_articles[idx]['title']), '\\n\\n')\n",
    "v = nlp(parsed_articles[idx]['abstract']).vector\n",
    "query = np.array([v])\n",
    "\n",
    "scores, results = index.search(query, n_near_docs) \n",
    "for i, result in enumerate(results[0]):\n",
    "    print(i+1, result, parsed_articles[result]['title'], ' - vector distance: ', scores[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd057dfa-7393-45d2-88a6-0d03185e53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the index for further usage\n",
    "faiss.write_index(index, '../faiss_index.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6a45203-53d8-4bd4-aab6-9ea6910a46f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index = faiss.read_index('../faiss_index.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10021e50-3edd-4723-95f1-a8174c02410f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
